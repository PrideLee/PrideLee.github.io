---
title: "Improving End-to-End Memory Networks with Unified Weight Tying"
collection: publications
permalink: /publication/altw-2017
date: 2017-12-07
venue: 'Proceedings of the Australasian Language Technology Association Workshop 2017 (ALTW 2017)'
paperurl: 'http://aclweb.org/anthology/U17-1002'
paperurltext: 'Link to ACL anthology'
citation: '<b>Fei Liu</b>, Trevor Cohn and Timothy Baldwin (2017) <a href="http://liufly.github.io/files/papers/naaclhtl-2018.pdf"><u>Improving End-to-End Memory Networks with Unified Weight Tying</u></a>, In <i>Proceedings of the Australasian Language Technology Association Workshop 2017 (ALTW 2017)</i>, Brisbane, Australia, pp. 16-24. <strong style="color: red;">Best Poster Award</strong>
'
---

```
@inproceedings{Liu+:2017,
  author    = {Liu, Fei and Cohn, Trevor and Baldwin, Timothy},
  title     = {Improving End-to-End Memory Networks with Unified Weight Tying},
  booktitle = {Proceedings of the Australasian Language Technology Association Workshop 2017 (ALTW 2017)},
  year      = {2017},
  address   = {Brisbane, Australia},
  pages     = {16--24}
}
```

## Abstract
Answering questions while reasoning over multiple supporting facts has long been a goal of artificial intelligence. Recently, remarkable advances have been made, focusing on reasoning over natural language-based stories. In particular, end-to-end memory networks (N2N), have achieved state-of-the-art results over such tasks. However, N2Ns are limited by the necessity to choose between two weight tying schemes, neither of which performs consistently well over all tasks. We propose a unified model generalising weight tying and in doing so, make the model more expressive. The proposed model achieves uniformly high performance, improving on the best results for memory network-based models on the bAbI dataset, and competitive results on Dialog bAbI.